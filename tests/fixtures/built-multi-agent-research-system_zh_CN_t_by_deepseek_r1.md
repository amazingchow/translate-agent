## 我们如何构建多代理研究系统

> 我们的"研究"功能通过多个Claude代理协同工作，显著提升复杂课题的探索效率。本文分享构建该系统中面临的工程挑战及总结的关键经验。

Claude现支持[研究功能](https://www.anthropic.com/news/research)，可跨网络、Google Workspace及各类集成系统执行复杂任务。

该多代理系统从原型开发到正式投产的实践过程，让我们在系统架构、工具设计和提示工程三大领域收获了至关重要的经验。多代理系统由多个通过工具循环自主运作的代理（大语言模型）协同工作构成。我们的研究功能包含规划代理（依据用户查询设计研究流程）和搜索代理（由工具创建并行执行信息检索）两类主体。这类系统在代理协同、效能评估和运行可靠性方面引发了全新挑战。

本文解析经我们实践验证的核心设计原则——这些经验对您构建自有多代理系统具有参考价值。



### 研究架构概览
我们的研究系统采用基于协调者-工作者模式的多智能体架构，其中领导智能体负责协调整个流程，并将任务委派给并行运作的专用子智能体（从属智能体）。
![The multi-agent architecture in action](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1198befc0b33726c45692ac40f764022f4de1bf2-4584x2579.png&w=3840&q=75)
> 运作中的多智能体架构：用户查询通过主导智能体流转，该智能体创建专用子智能体并行搜索不同维度信息。

当用户提交查询时，主导智能体分析查询内容、制定策略，并调遣子智能体同步探索不同维度。如本例所示（如上图示意），这些子智能体作为智能筛选器，通过迭代使用搜索工具收集信息（具体针对2025年AI智能体公司数据），随后将公司名单返回主导智能体，由其汇编最终答案。

采用检索增强生成（RAG）的传统方法使用静态检索机制，即获取与输入查询最相似的若干数据片段，并基于这些片段生成响应。与之相反，我们的架构采用多步骤搜索：动态定位相关信息，即时适应新发现，并通过结果分析制定高质量答案。
![The multi-agent system process diagram](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F3bde53c9578d74f6e05c3e515e20b910c5a8c20a-4584x4584.png&w=3840&q=75)
流程图示展示我们多智能体研究系统的完整工作流程。当用户提交查询时，系统创建主导研究员（LeadResearcher）智能体，进入迭代研究流程。主导研究员首先通过思考制定方案，并将计划保存至记忆库以持久化上下文——因上下文窗口超过200,000 Token时将被截断，保留计划至关重要。随后创建专项子智能体（Subagents）（此处展示两个，实际数量可灵活调整）并分配特定研究任务。每个子智能体独立执行网络搜索，运用[交错思考法](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking)评估工具结果，并将发现返回主导研究员。主导研究员综合这些结果，判定是否需要进一步研究——若需深入研究，可创建额外子智能体或调整研究策略。收集足够信息后，系统退出研究循环，将所有发现移交引文处理智能体（CitationAgent）。该智能体分析文档和研究报告，定位具体引文位置，确保所有主张均准确标注来源。最终将附有完整引用的研究结果返回用户。

### 面向研究型智能体的提示词工程与效果评估

多智能体系统与单智能体系统存在关键差异，其协调复杂性呈指数级增长。早期智能体常出现各种故障行为：为简单查询创建50个子智能体、无休止搜寻不存在的资源、因过度更新互相干扰。由于每个智能体均由提示词驱动，提示词工程成为优化这些行为的核心手段。以下是我们在提示词设计过程中总结的核心原则：

1. **化身智能体思考**。优化提示词前需理解其作用机制。为辅助这一过程，我们使用[控制台](https://console.anthropic.com/)搭建模拟环境，植入完整提示词与工具系统，逐步观察智能体行为。该方法即时暴露了多种失效模式：获得充分结果后仍继续操作、使用过度冗长的搜索语句、错误选择工具。建立精确的智能体行为心智模型后，最关键的改进点往往不言自明。

2. **教导编排器分配任务**。在本系统中，主控智能体将查询分解为子任务并分配给子智能体。每个子智能体需要清晰的目标说明、输出格式要求、工具使用指南及任务边界定义。缺乏详细任务描述会导致工作重复、信息遗漏或关键数据缺失。初期我们允许主控智能体发布简指令（如"研究芯片短缺问题"），但发现这类模糊指令常使子智能体误解任务或重复执行相同搜索——例如曾有子智能体研究2021年汽车芯片危机，而另外两个子智能体却重复调研2025年供应链现状，完全缺失分工协作。

3. **按查询复杂度匹配资源规模**。智能体难以自主判断任务所需资源量，因此我们将规模规则嵌入提示词：简单事实查询仅需1个智能体（3-10次工具调用）；对比分析可能需要2-4个子智能体（各10-15次调用）；复杂研究则需10个以上明确分工的子智能体。这些显性规则帮助主控智能体高效配置资源，有效杜绝了早期版本中简单查询过度消耗资源的常见故障。

4. **工具设计与选择至关重要**。智能体与工具的交互界面如同人机界面般关键。正确选用工具不仅能提升效率，更是成功的前提——例如试图通过网页搜索获取仅存在于Slack的上下文从一开始就注定失败。在接入[MCP服务器（模型上下文协议服务器）](https://modelcontextprotocol.io/introduction)扩展工具库后，问题更趋复杂：智能体面临未知工具，而工具描述质量参差不齐。我们为智能体设置了明确启发规则：优先审查所有可用工具、根据用户意图匹配工具、使用网页搜索进行外部探索、优先选用专用工具而非通用工具。糟糕的工具描述会引导智能体彻底偏离正轨，因此每个工具都需要独特功能定位与清晰说明文档。

5. **引导智能体自我优化**。Claude 4系列模型展现卓越的提示工程能力：当获取某条提示词及其故障案例时，它们能诊断失效根源并提出改进方案。我们甚至开发了工具测试智能体——当输入存在缺陷的MCP工具时，该智能体尝试使用后重写工具描述以避免故障。通过数十次测试，该智能体成功发现关键细节与程序缺陷。优化后的工具描述使后续智能体任务完成时间缩短了40%，因其规避了绝大多数操作错误。

6. **先广度扫描，后深度聚焦**。搜索策略应模拟人类专家研究模式：先建立全局认知再深入细节。智能体常默认使用冗长且过细的查询语句，导致返回结果寥寥。我们在提示词中驱动智能体启动简短宽泛的初始查询评估资源概况，再逐步收窄搜索范围。

7. **引导思考进程**。[扩展思考模式](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking)驱动Claude输出可视化思维过程，可作为可控草稿空间。主控智能体借此规划任务路径：筛选适用工具、评估查询复杂度、设定子智能体数量、定义各角色职责。测试表明该模式显著提升指令遵循性、推理能力及效率。子智能体同样先规划方案，随后在工具调用间隙采用[交叉思考](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking)评估结果质量、识别信息缺口、优化后续查询策略，从而增强任务适应能力。

8. **并行工具调用颠覆性能表现**。复杂研究天然涉及多源信息探索。早期智能体采用串行搜索模式导致效率低下。为提速我们引入两种并行机制：(1)主控智能体同时激活3-5个子智能体；(2)子智能体并行调用3个以上工具。该改进使复杂查询的研究时间缩短90%，研究系统数分钟内即可完成传统需数小时的工作量，且覆盖信息量远超其他系统。

我们的提示策略重在植入优质启发规则而非僵化指令。通过研究人类专家的工作范式，将这些策略编码进提示系统：拆解复杂问题为子任务、谨慎评估信源质量、根据新信息调整搜索策略、平衡深度挖掘（专题研究）与广度探索（并行调研）。同时预设明确防护栏机制，主动预防智能体失控风险。最后，我们通过可视化监控与测试案例构建高速迭代闭环。

### AI智能体的有效评估

构建可靠的AI应用离不开优秀评估体系，AI智能体领域同样如此。然而评估多智能体系统存在独特挑战。传统方法通常预设固定路径：给定输入X，系统须经路径Y产出输出Z。但多智能体系统的运作逻辑截然不同。即使起点完全相同，智能体也可能通过截然不同的有效路径达成目标——某个智能体可能检索三个数据源，另一个则检索十个；它们也可能借助不同工具获得相同答案。由于我们无法预知"正确"路径，通常不能简单检验智能体是否遵循预设步骤。关键在于建立能判定"智能体是否通过合理过程达成正确结果"的灵活评估框架。

**从小样本起步开展即时评估**。智能体开发早期存在大量唾手可得的优化机会，细微变更常产生显著效果。简单调整提示词可能使成功率从30%跃升至80%。当效果差异如此显著时，仅需少量测试案例即可验证改进。我们采用20个代表真实场景的查询案例进行测试，常能清晰观察到改动影响。许多AI团队误认为必须构建含数百案例的评估体系才有效，因而推迟评估工作。实际上，立即启动小规模测试远比等待"完美"评估方案更务实。

**LLM即法官评估经优化后具备高度可扩展性**。研究输出多为自由文本且罕有唯一标准答案，难以程序化评估。大语言模型天然胜任评分工作：我们部署的LLM法官会基于多维标准进行评估，包括事实准确性（主张与来源是否吻合）、引文可靠性（引用是否切实支持论点）、内容完备性（是否覆盖所有需求要点）、来源质量（是否优先选用一手信源而非低质二手内容）、工具效率（是否合理使用恰当工具）。尽管尝试过多个法官分项评分，但最终证实单次LLM调用输出0.0-1.0分数及通过/未评级的方案，其稳定性最高且与人工评估最契合。当测试案例存在明确答案时（例如"能否准确列举研发预算前三的药企"），该方案成效尤为显著。这种策略让我们具备规模化处理数百项输出的评估能力。

**人工评估捕捉自动化盲点**。人员测试能发现评估遗漏的边缘场景：非常规查询引发的虚构答案、系统崩溃、隐蔽的来源选择偏好等。案例中，测试员发现早期智能体持续偏好SEO内容农场，却忽视学术PDF或个人博客等权威性高但搜索排名低的资源。通过在提示词中嵌入来源质量优化机制，该问题得以解决。即使自动化评估日益成熟，人工测试始终是不可替代的关键环节。

多智能体系统具备涌现行为特性（指系统整体表现超出个体功能之和的特性）。例如主智能体的微调可能不可预测地改变子智能体行为模式。成功关键不仅在于理解个体行为，更需掌握交互规律。因此最佳提示词不仅是操作指令，更应构建定义职责分工、解题方法及工作量预算的协作框架。实现该目标需要：精心的提示词与工具设计、可靠的优化策略、完善的可观测机制及高效的反馈闭环。请参见[Cookbook开源提示词库](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents/prompts)获取我们系统的示例模板。

### 生产可靠性与工程挑战

在传统软件中，一个缺陷可能破坏某项功能、降低性能或导致服务中断。而在智能体系统中，微小改动会引发连锁反应导致行为剧变，编写复杂智能体代码的难度因此大幅增加——这些智能体需要在长时间运行流程中持续维护状态。

**智能体具有状态持续性，错误会产生累积效应。** 智能体可能长时间运行，在多次工具调用中保持状态记忆。这意味着我们需要持久化执行代码并全程管控错误。缺乏有效缓解机制时，微小系统故障对智能体具有灾难性影响。错误发生时不能简单重启：重启资源消耗高且损害用户体验。为此我们构建了智能体故障点续执系统，同时利用模型智能实现优雅降级：例如当工具失效时通知智能体并让其自主调整，这种策略实际效果显著。我们将基于Claude的AI智能体自适应能力与重试逻辑（含指数退避策略）、定期检查点等确定性保障机制相结合。

**调试需采用创新方法论。** 智能体基于实时环境进行动态决策，即便使用相同提示词，跨次运行也呈现非确定性特征，显著增加调试难度。典型案例是用户报告"智能体未能识别明显信息"时，我们曾无法定位根因：搜索词是否不当？信源选择失误？工具接口故障？实施全链路追踪后，才能系统化诊断故障并修复。在基础可观测性之上，我们还监控智能体决策模式与交互拓扑结构——全程严守单个对话内容隐私，这种抽象层级的观测系统帮助我们精确定位根因、发现非预期行为并修复共性故障。

**部署需要精密协同。** 智能体系统是由提示词、工具和执行逻辑编织的高度状态化网络，具备准持续运行特性。任何部署更新发生时，既有智能体可能处于流程任意阶段。因此必须阻断善意代码变更对运行中智能体的破坏性影响。由于无法全局瞬时升级，我们采用[彩虹部署方案](https://brandon.dimcheff.com/2018/02/rainbow-deploys-with-kubernetes/)（即版本回放机制），通过在旧版与新版间渐进迁移流量（保持双版本并行运行）实现零干扰升级。

**同步执行造成协作瓶颈。** 当前主控智能体采用同步策略调度子智能体，必须等待每组子智能体完成才推进后续流程。这种模式简化了协调机制，却造成智能体间的信息传递瓶颈。典型问题包括：主控智能体无法动态引导子智能体，子智能体间缺乏协作能力，整个系统常因单个子智能体搜索未完成而全局阻塞。异步执行能释放并发潜力：智能体并行工作，必要时动态生成子智能体。但这会引入子智能体结果聚合协调、分布式状态一致性及错误跨层传播等新挑战。随着模型处理长周期复杂研究任务的能力进化，我们预期性能提升将抵消其增加的复杂度成本。

构建AI智能体时，最后一步往往演变为主要征程。能在开发环境运行的代码库需经过大量工程改造才能成为可靠的生产系统。智能体系统错误的复合性特性意味着：传统软件中的微小问题，就可能导致智能体完全失控。单步失败会触发智能体探索全然不同的执行路径，引发不可预测的后果。基于本文所述的所有原因，原型与生产环境之间的鸿沟通常远超预期。

尽管存在这些挑战，多智能体系统已在开放式研究任务中证明其重要价值。用户反馈显示，Claude帮助他们发掘了未曾考虑的商业机遇，梳理了复杂的医疗选项，修复了顽固的技术漏洞，并通过发现独立研究难以建立的关键关联节省高达数天时间。通过精细的工程实现、全面测试、注重细节的提示词与工具设计、稳健的运维实践，以及深刻理解当前智能体能力的研究/产品/工程团队紧密协作，多智能体研究系统能够实现规模化可靠运行。我们正见证这些系统深度变革人类解决复杂问题的方式。
![A Clio embedding plot](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F09a90e0aca54859553e93c18683e7fd33ff16d4c-2654x2148.png&w=3840&q=75)
>[Clio](https://www.anthropic.com/research/clio)嵌入图展示了当前人们使用研究功能的最常见方式。前五大用例类别分别是：跨专业领域开发软件系统（10%）、开发优化专业技术内容（8%）、制定业务增长和创收策略（8%）、协助学术研究与教材开发（7%）、以及研究与核实人员/地点/组织相关信息（5%）。

### 附录  
以下是关于多智能体系统的补充技术要点：  

**状态持续修改型智能体的终态评估方案**  
评估在多轮对话中持续修改持久化状态的智能体存在特殊挑战。与只读研究任务不同，每个动作都可能改变后续步骤的环境，形成传统评估方法难以处理的依赖链。我们采用的终态评估方案（区别于逐轮分析）效果显著：不关注智能体是否遵循特定流程，而聚焦其能否达成正确的最终状态。该方法既承认智能体可通过不同解决方案路径达成相同目标，又能确保最终输出符合预期。对于复杂工作流，需将评估拆分为离散检查点——要求特定状态变更必须完成，而非验证每个中间环节。  

**长程对话的上下文管理策略**  
生产环境中的智能体常需管控数百轮对话，必须实施精细的上下文管理机制。随着对话持续延伸，常规上下文窗口逐渐不足，此时需部署智能压缩与记忆模块。具体实现模式：智能体在完成工作阶段后执行渐进式总结，将核心信息存入外部记忆库再开启新任务；当临近上下文容量阈值时，启动带纯净上下文的新子智能体，并通过精准的上下文传递维持连续性；同时支持从记忆库（如研究计划）检索历史上下文，避免工作成果因超限丢失。这种分布式架构在维持跨会话连贯性的同时，有效规避了上下文溢出风险。  

**子智能体直存文件系统：解决传话失真问题**  
特定类型的子智能体输出可绕过主协调器直接持久化存储，同时提升结果保真度与系统性能。通过建立工件系统，使专业化子智能体能生成持久化独立产物：子智能体调用工具将成果存入外部系统，仅向协调器返回轻量引用符。此举既规避多阶段处理中的信息衰减，又显著降低因大体积输出在对话历史中重复占用导致的token开销。该模式尤其适用于代码文件、数据报告及可视化图表等结构化输出场景，此时子智能体的专用提示词所产生的效果，远优于经过通用协调器过滤的间接输出。