import os
import re
import time
from typing import List, Tuple

import fire

from translate_by_deepseek import generate_in_non_stream_mode as translate_by_deepseek

# --- é…ç½®é¡¹ ---
MAX_CHUNK_SIZE = 100000


class TranslateAgent:
    """
    TranslateAgent is a class that translates a Markdown file into a bilingual format.
    """

    def run(self, file_path: str, keep_original: bool = False, output_path: str = None) -> None:
        try:
            with open(file_path, encoding="utf-8") as f:
                markdown_content = f.read()
        except FileNotFoundError:
            print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ {file_path} ä¸å­˜åœ¨ã€‚")
            return
        if not output_path:
            output_path = file_path.replace(".md", "_zh_CN.md")
        print(f"âœ… å¼€å§‹ç¿»è¯‘ä»»åŠ¡: {file_path} -> {output_path}")

        # 1. æŒ‰æ ‡é¢˜å°†æ–‡ç« åˆ†å‰²æˆè¯­ä¹‰å—
        sections = self.split_into_sections_by_headings(markdown_content)
        total_sections = len(sections)
        print(f"âœ… æ–‡ç« å·²æŒ‰æ ‡é¢˜åˆ†å‰²æˆ {total_sections} ä¸ªä¸»è¦éƒ¨åˆ†ã€‚")

        # 2. éå†æ¯ä¸ªéƒ¨åˆ†è¿›è¡Œå¤„ç†
        final_bilingual_parts = []
        for i, (heading, section_content) in enumerate(sections):
            print(
                f"ğŸš§ æ­£åœ¨å¤„ç† [{i + 1}/{total_sections}] éƒ¨åˆ†: \n æ ‡é¢˜: {heading.strip() if heading else 'Preamble'}\n å†…å®¹: {section_content[:256]} ..."
            )

            # ç¿»è¯‘éƒ¨åˆ†å†…å®¹ï¼ˆæ­¤å‡½æ•°å†…éƒ¨ä¼šå¤„ç†ä»£ç å—ã€è¡¨æ ¼ã€é“¾æ¥ã€å›¾ç‰‡ã€è¶…é•¿å—ï¼‰
            original_part = f"{heading}{section_content}"
            translated_section_content = self.process_and_translate_text_chunk(original_part)

            # 3. ç»„åˆæˆä¸­è‹±äº¤æ›¿æ ¼å¼
            # final_bilingual_parts.append(original_part.strip())
            final_bilingual_parts.append(translated_section_content.strip())

        # 4. å†™å…¥è¾“å‡ºæ–‡ä»¶
        final_content = "\n\n".join(final_bilingual_parts)
        try:
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(final_content)
            print(f"\nğŸ‰ ç¿»è¯‘å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {output_path}")
            if not keep_original:
                os.remove(file_path)
        except OSError as e:
            print(f"âŒ é”™è¯¯: æ— æ³•å†™å…¥æ–‡ä»¶ at {output_path}. Error: {e}")

    @staticmethod
    def split_into_sections_by_headings(markdown_content: str) -> List[Tuple[str, str]]:
        if not markdown_content.strip():
            return []

        # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä»¥'#'å¼€å¤´çš„è¡Œ (æ ‡é¢˜), re.splitä¼šå°†åˆ†éš”ç¬¦ä¹Ÿä¿ç•™åœ¨åˆ—è¡¨ä¸­
        parts = re.split(r"(^#+ .*$)", markdown_content, flags=re.MULTILINE)

        sections = []
        # ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æ–‡ç« å¼€å¤´åˆ°ç¬¬ä¸€ä¸ªæ ‡é¢˜å‰çš„å†…å®¹
        if len(parts) > 0 and parts[0].strip():
            sections.append(("", parts[0]))

        # ä»ç¬¬äºŒä¸ªå…ƒç´ å¼€å§‹ï¼Œæ¯ä¸¤ä¸ªå…ƒç´ ç»„æˆä¸€ä¸ª (æ ‡é¢˜, å†…å®¹) å¯¹
        for i in range(1, len(parts), 2):
            heading = parts[i]
            section_content = parts[i + 1] if (i + 1) < len(parts) else ""
            sections.append((heading, section_content))

        return sections

    def process_and_translate_text_chunk(self, text_chunk: str) -> str:
        if not text_chunk.strip():
            return ""

        # 1. åˆ†ç¦»å‡ºä¸éœ€è¦ç¿»è¯‘çš„å†…å®¹
        parts = self.split_by_special_content(text_chunk)
        print(f"âœ… æ–‡æœ¬å—å·²æŒ‰ç‰¹æ®Šå†…å®¹åˆ†å‰²æˆ {len(parts)} ä¸ªéƒ¨åˆ†ã€‚")

        translated_parts = []
        for part in parts:
            if not part.strip():
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹æ®Šå†…å®¹ï¼ˆä»£ç å—ã€è¡¨æ ¼ã€å›¾ç‰‡ï¼‰
            is_special_content = (
                part.startswith("```")  # ä»£ç å—
                or part.startswith("|")  # è¡¨æ ¼
                or part.startswith("![")  # å›¾ç‰‡
            )
            if is_special_content:
                # ç‰¹æ®Šå†…å®¹åŸæ ·ä¿ç•™
                translated_parts.append(f"\n{part}\n")
                continue

            # å¯¹äºæ™®é€šæ–‡æœ¬éƒ¨åˆ†ï¼Œè¿›è¡Œå¤§å°æ£€æŸ¥å’Œé€’å½’å¤„ç†
            if len(part) <= MAX_CHUNK_SIZE:
                # å°äºé™åˆ¶ï¼Œç›´æ¥ç¿»è¯‘
                translated_parts.append(self.translate(part))
            else:
                # å—å¤ªå¤§ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²
                print(
                    f"  - [é€’å½’åˆ†å‰²] å—å¤§å°ä¸º {len(part)} å­—ç¬¦ï¼Œè¶…è¿‡é™åˆ¶ï¼ˆ{MAX_CHUNK_SIZE} ä¸ªå­—ç¬¦ï¼‰ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²..."
                )
                raise ValueError(f"å—å¤§å°ä¸º {len(part)} å­—ç¬¦ï¼Œè¶…è¿‡é™åˆ¶ï¼ˆ{MAX_CHUNK_SIZE} ä¸ªå­—ç¬¦ï¼‰ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²...")

        return "".join(translated_parts)

    @staticmethod
    def split_by_special_content(markdown_content: str) -> List[str]:
        if not markdown_content.strip():
            return []

        # ä»£ç å— - ä½¿ç”¨éè´ªå©ªåŒ¹é…
        code_pattern = r"(```[\s\S]*?```)"
        # è¡¨æ ¼ - ç¡®ä¿è¡¨æ ¼è¡Œä¹‹é—´æœ‰æ¢è¡Œç¬¦
        table_pattern = r"(\|[^\n]*\|(?:\n\|[^\n]*\|)+)"
        # å›¾ç‰‡ - ä½¿ç”¨éè´ªå©ªåŒ¹é…
        image_pattern = r"(!\[[^\]]*?\]\([^\)]+?\))"
        # ç»„åˆæ‰€æœ‰æ¨¡å¼ï¼Œä½¿ç”¨éæ•è·ç»„
        combined_pattern = f"(?:{code_pattern}|{table_pattern}|{image_pattern})"
        # ä½¿ç”¨ re.split ä¿ç•™åˆ†éš”ç¬¦
        parts = re.split(combined_pattern, markdown_content)
        # è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²
        return [part for part in parts if part]

    def translate(self, content: str) -> str:
        if not content.strip():
            return ""
        st = time.time()
        result = translate_by_deepseek(content)
        print(f"âœ… ç¿»è¯‘è€—æ—¶: {time.time() - st:.2f} ç§’")
        return result


if __name__ == "__main__":
    fire.Fire(TranslateAgent)
